<Numerical Simulation 셋팅/설계>

m : small area 개수 (100,500, 1000) 

beta : (20, 1)
X : fixed
V : error variance 
u : random effects <- generated by 5 settings

=====================================================================================================================================
<JASA논문 시뮬레이션 방식>
1. sigma^2에 대한 prior에 따른 sensitivity analysis
ㄴ 우리의 경우 inverse-gamma로 고정인데. 


2. 평가방식 : 5개의 evaluation metric
3. 다른 모델과 비교(gl 논문 기준)
(ours)
 - GLLASSO : implemented
 - BEN : implemented. 
(기존)
 - FH : sigma^2 에 대하여 uniform prior 사용. (implemented) / Beta 에 대하여 improper uniform
 - DM : p : beta(1,4) 
        sigma^2 : inverse gamma with mean V_bar and variance V^2 : known variances for error term.
        p : 
 - GL : various for lambda^2 <- 다양한 prior 시도. what to choose? 일단 다양한 셋팅하에서 작동하도록 설계.
      - 알고리즘을 간단하게 할 수 있는 prior 시도
        (1)- tau <- halfcauchy(scale = 1)
           - lambda^2 ~ exp(1) 

4. 추가적으로 각 모델 original paper과 비교한 검증이 필요함.
5. 서버  분산 처리 구현이 필수적.



<250817>

1. STAN에서 hamiltonian mcmc <- E-BFMI 문제? <- 해결
2. global-local shrinkage 간 non-identifiability? 괜찮은가? <- 다시 공부해보기.
4. rho의 값 문제? 증가함수꼴로 보이는데


<250819>

1. 메모리 문제 <- 모든 체인 보관 대신에 theta.hat, coverage 정도만 보기. + 추가로 각 체인 수렴여부정도는 파악해야 할 듯 한데?
2. 그래도 소수샘플은 남겨야...


<250825>
1. real data 분석 결과: 심각한 문제가 있음
ㄴ mcem rho 추정이 잘 되고 있는건가?
ㄴ BEN은 수렴은 잘 됨.
ㄴ lasso sampler 수렴이 잘 안되는 이유? <- 뭔가 잘못되지 않았을 까 싶다.


2. lasso sampler의 수렴시간은 왜이리 오래걸릴까 <- 파라미터가 너무 많기 때문.
3. non identifiability?
4. 평가기준으로 DIC가 최선인가? 다른 척도를 사용해봐도 괜찮을 것 같다.
5. shrinkage factor 계산해야함
6. 메사추세츠는 22번째 주.
7. BEN : 메사추세츠에서도 shrinkage 시키고 있음. -> hyper parameter 설정에 따라 다름. 어떻게 선택해야 할까?
8.

